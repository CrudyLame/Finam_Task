import streamlit as st
import json
import pandas as pd
import plotly.express as px
import plotly.graph_objects as go
from pathlib import Path
from datetime import datetime
from collections import Counter
import numpy as np

# Page config
st.set_page_config(
	page_title="–ü–∞–Ω–µ–ª—å –ê–Ω–∞–ª–∏—Ç–∏–∫–∏ Finam",
	page_icon="üìä",
	layout="wide",
	initial_sidebar_state="expanded"
)

@st.cache_data
def load_conversation_data():
	"""Load and cache conversation data"""
	data_path = Path(__file__).parent.parent / "conversations_data.json"
	with open(data_path, 'r', encoding='utf-8') as f:
		data = json.load(f)
	return data

def get_category_stats(conversations):
	"""Extract category statistics from conversations"""
	categories = []
	intents = []
	
	for conv in conversations:
		if 'analysis' in conv and 'request' in conv['analysis']:
			request_analysis = conv['analysis']['request']
			categories.extend(request_analysis.get('category', []))
			intents.extend(request_analysis.get('intent', []))
	
	return Counter(categories), Counter(intents)

def get_problems_stats(conversations):
	"""Extract problems statistics from conversations"""
	problems = []
	
	for conv in conversations:
		if 'analysis' in conv and 'problems' in conv['analysis']:
			problems.extend(conv['analysis']['problems'].get('problems', []))
	
	return Counter(problems)

def get_ux_stats(conversations):
	"""Extract UX and sentiment statistics from conversations"""
	sentiments = []
	emotions = []
	success_rates = []
	feedback_count = 0
	suggestions_count = 0
	
	for conv in conversations:
		if 'analysis' in conv and 'ux' in conv['analysis']:
			ux_analysis = conv['analysis']['ux']
			if 'sentiment' in ux_analysis:
				sentiments.append(ux_analysis['sentiment'])
			emotions.extend(ux_analysis.get('emotions', []))
			success_rates.append(ux_analysis.get('is_successful', False))
			feedback_count += len(ux_analysis.get('feedback', []))
			suggestions_count += len(ux_analysis.get('suggestions', []))
	
	return {
		'sentiments': Counter(sentiments),
		'emotions': Counter(emotions),
		'success_rate': sum(success_rates) / len(success_rates) if success_rates else 0,
		'feedback_count': feedback_count,
		'suggestions_count': suggestions_count
	}

def main():
	st.title("üìä –ü–∞–Ω–µ–ª—å –ê–Ω–∞–ª–∏—Ç–∏–∫–∏ –ú—É–ª—å—Ç–∏–∞–≥–µ–Ω—Ç–Ω–æ–π –°–∏—Å—Ç–µ–º—ã Finam")
	
	# Load data
	try:
		data = load_conversation_data()
		conversations = data['conversations']
		metadata = data['metadata']
	except Exception as e:
		st.error(f"Failed to load data: {str(e)}")
		return
	
	# Sidebar navigation
	st.sidebar.title("–ù–∞–≤–∏–≥–∞—Ü–∏—è")
	page = st.sidebar.selectbox(
		"–í—ã–±–µ—Ä–∏—Ç–µ —Ç–∏–ø –∞–Ω–∞–ª–∏–∑–∞",
		["–û–±–∑–æ—Ä", "–ê–Ω–∞–ª–∏–∑ –∫–∞—Ç–µ–≥–æ—Ä–∏–π", "–ê–Ω–∞–ª–∏–∑ –ø—Ä–æ–±–ª–µ–º", "UX –∞–Ω–∞–ª–∏–∑", "–ü—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å –∞–≥–µ–Ω—Ç–æ–≤"]
	)
	
	# Overview metrics
	st.sidebar.markdown("---")
	st.sidebar.metric("–í—Å–µ–≥–æ –¥–∏–∞–ª–æ–≥–æ–≤", metadata['total_conversations'])
	st.sidebar.metric("–î–∞–Ω–Ω—ã–µ –æ–±–Ω–æ–≤–ª–µ–Ω—ã", metadata['last_updated'][:10])
	
	if page == "–û–±–∑–æ—Ä":
		show_overview(conversations, metadata)
	elif page == "–ê–Ω–∞–ª–∏–∑ –∫–∞—Ç–µ–≥–æ—Ä–∏–π":
		show_category_analysis(conversations)
	elif page == "–ê–Ω–∞–ª–∏–∑ –ø—Ä–æ–±–ª–µ–º":
		show_problems_analysis(conversations)
	elif page == "UX –∞–Ω–∞–ª–∏–∑":
		show_ux_analysis(conversations)
	elif page == "–ü—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å –∞–≥–µ–Ω—Ç–æ–≤":
		show_agent_performance(conversations)

def show_overview(conversations, metadata):
	st.header("üìà –û–±–∑–æ—Ä")
	
	col1, col2, col3, col4 = st.columns(4)
	
	# Basic metrics
	avg_duration = np.mean([conv['duration_minutes'] for conv in conversations])
	avg_messages = np.mean([conv['message_count'] for conv in conversations])
	unique_users = len(set(conv['user_id'] for conv in conversations))
	
	with col1:
		st.metric("–°—Ä–µ–¥–Ω—è—è –ø—Ä–æ–¥–æ–ª–∂–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å (–º–∏–Ω)", f"{avg_duration:.2f}")
	with col2:
		st.metric("–°—Ä–µ–¥–Ω–µ–µ –∫–æ–ª-–≤–æ —Å–æ–æ–±—â–µ–Ω–∏–π", f"{avg_messages:.1f}")
	with col3:
		st.metric("–£–Ω–∏–∫–∞–ª—å–Ω—ã—Ö –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–π", unique_users)
	with col4:
		st.metric("–ü–æ–∫–∞–∑–∞—Ç–µ–ª—å —É—Å–ø–µ—Ö–∞", f"{get_ux_stats(conversations)['success_rate']:.1%}")
	
	# Timeline analysis
	st.subheader("üìÖ –•—Ä–æ–Ω–æ–ª–æ–≥–∏—è –¥–∏–∞–ª–æ–≥–æ–≤")
	
	# Extract dates and create timeline
	dates = [datetime.fromisoformat(conv['start_time']).date() for conv in conversations]
	date_counts = Counter(dates)
	
	timeline_df = pd.DataFrame(list(date_counts.items()), columns=['Date', 'Count'])
	timeline_df = timeline_df.sort_values('Date')
	
	fig = px.line(timeline_df, x='Date', y='Count', title="–ï–∂–µ–¥–Ω–µ–≤–Ω—ã–π –æ–±—ä–µ–º –¥–∏–∞–ª–æ–≥–æ–≤")
	st.plotly_chart(fig, use_container_width=True)

def show_category_analysis(conversations):
	st.header("üè∑Ô∏è –ê–Ω–∞–ª–∏–∑ –∫–∞—Ç–µ–≥–æ—Ä–∏–π")
	
	categories, intents = get_category_stats(conversations)
	
	col1, col2 = st.columns(2)
	
	with col1:
		st.subheader("–ö–∞—Ç–µ–≥–æ—Ä–∏–∏ –∑–∞–ø—Ä–æ—Å–æ–≤")
		if categories:
			fig = px.pie(
				values=list(categories.values()),
				names=list(categories.keys()),
				title="–†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –∫–∞—Ç–µ–≥–æ—Ä–∏–π –∑–∞–ø—Ä–æ—Å–æ–≤"
			)
			st.plotly_chart(fig, use_container_width=True)
		else:
			st.info("–ù–µ—Ç –¥–∞–Ω–Ω—ã—Ö –æ –∫–∞—Ç–µ–≥–æ—Ä–∏—è—Ö")
	
	with col2:
		st.subheader("–ù–∞–º–µ—Ä–µ–Ω–∏—è –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–π")
		if intents:
			fig = px.bar(
				x=list(intents.keys()),
				y=list(intents.values()),
				title="–†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –Ω–∞–º–µ—Ä–µ–Ω–∏–π –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–π"
			)
			st.plotly_chart(fig, use_container_width=True)
		else:
			st.info("–ù–µ—Ç –¥–∞–Ω–Ω—ã—Ö –æ –Ω–∞–º–µ—Ä–µ–Ω–∏—è—Ö")
	
	# Detailed breakdown
	st.subheader("üìä –ü–æ–¥—Ä–æ–±–Ω–∞—è —Ä–∞–∑–±–∏–≤–∫–∞")
	
	if categories:
		category_df = pd.DataFrame(list(categories.items()), columns=['–ö–∞—Ç–µ–≥–æ—Ä–∏—è', '–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ'])
		category_df['–ü—Ä–æ—Ü–µ–Ω—Ç'] = (category_df['–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ'] / category_df['–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ'].sum() * 100).round(2)
		st.dataframe(category_df, use_container_width=True)

def show_problems_analysis(conversations):
	st.header("‚ö†Ô∏è –ê–Ω–∞–ª–∏–∑ –ø—Ä–æ–±–ª–µ–º")
	
	problems = get_problems_stats(conversations)
	
	if problems:
		col1, col2 = st.columns([2, 1])
		
		with col1:
			# Problem frequency chart
			fig = px.bar(
				x=list(problems.values()),
				y=list(problems.keys()),
				orientation='h',
				title="–ß–∞—Å—Ç–æ—Ç–∞ –≤–æ–∑–Ω–∏–∫–Ω–æ–≤–µ–Ω–∏—è –ø—Ä–æ–±–ª–µ–º"
			)
			fig.update_layout(yaxis={'categoryorder':'total ascending'})
			st.plotly_chart(fig, use_container_width=True)
		
		with col2:
			st.subheader("–°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –ø—Ä–æ–±–ª–µ–º")
			total_problems = sum(problems.values())
			st.metric("–í—Å–µ–≥–æ —Å–ª—É—á–∞–µ–≤ –ø—Ä–æ–±–ª–µ–º", total_problems)
			st.metric("–£–Ω–∏–∫–∞–ª—å–Ω—ã—Ö —Ç–∏–ø–æ–≤ –ø—Ä–æ–±–ª–µ–º", len(problems))
			
			# Problem severity (mock classification for demo)
			st.subheader("–ö—Ä–∏—Ç–∏—á–Ω–æ—Å—Ç—å –ø—Ä–æ–±–ª–µ–º")
			high_severity = ["system_error", "data_loss", "security_breach"]
			medium_severity = ["performance_issue", "user_confusion", "timeout"]
			
			high_count = sum(problems.get(p, 0) for p in high_severity)
			medium_count = sum(problems.get(p, 0) for p in medium_severity)
			low_count = total_problems - high_count - medium_count
			
			severity_data = pd.DataFrame({
				'–ö—Ä–∏—Ç–∏—á–Ω–æ—Å—Ç—å': ['–í—ã—Å–æ–∫–∞—è', '–°—Ä–µ–¥–Ω—è—è', '–ù–∏–∑–∫–∞—è'],
				'–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ': [high_count, medium_count, low_count]
			})
			
			fig = px.pie(severity_data, values='–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ', names='–ö—Ä–∏—Ç–∏—á–Ω–æ—Å—Ç—å', 
						title="–†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –ø–æ –∫—Ä–∏—Ç–∏—á–Ω–æ—Å—Ç–∏")
			st.plotly_chart(fig, use_container_width=True)
		
		# Detailed problems table
		st.subheader("üìã –ü–æ–¥—Ä–æ–±–Ω—ã–π –æ—Ç—á–µ—Ç –æ –ø—Ä–æ–±–ª–µ–º–∞—Ö")
		problems_df = pd.DataFrame(list(problems.items()), columns=['–¢–∏–ø –ø—Ä–æ–±–ª–µ–º—ã', '–ß–∞—Å—Ç–æ—Ç–∞'])
		problems_df['–ü—Ä–æ—Ü–µ–Ω—Ç'] = (problems_df['–ß–∞—Å—Ç–æ—Ç–∞'] / problems_df['–ß–∞—Å—Ç–æ—Ç–∞'].sum() * 100).round(2)
		problems_df = problems_df.sort_values('–ß–∞—Å—Ç–æ—Ç–∞', ascending=False)
		st.dataframe(problems_df, use_container_width=True)
		
	else:
		st.info("–ù–µ—Ç –¥–∞–Ω–Ω—ã—Ö –æ –ø—Ä–æ–±–ª–µ–º–∞—Ö –≤ –¥–∏–∞–ª–æ–≥–∞—Ö")

def show_ux_analysis(conversations):
	st.header("üòä –ê–Ω–∞–ª–∏–∑ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å—Å–∫–æ–≥–æ –æ–ø—ã—Ç–∞")
	
	ux_stats = get_ux_stats(conversations)
	
	col1, col2, col3 = st.columns(3)
	
	with col1:
		st.metric("–ü–æ–∫–∞–∑–∞—Ç–µ–ª—å —É—Å–ø–µ—Ö–∞", f"{ux_stats['success_rate']:.1%}")
	with col2:
		st.metric("–û—Ç–∑—ã–≤—ã", ux_stats['feedback_count'])
	with col3:
		st.metric("–ü—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è", ux_stats['suggestions_count'])
	
	col1, col2 = st.columns(2)
	
	with col1:
		st.subheader("–†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –Ω–∞—Å—Ç—Ä–æ–µ–Ω–∏–π")
		if ux_stats['sentiments']:
			fig = px.pie(
				values=list(ux_stats['sentiments'].values()),
				names=list(ux_stats['sentiments'].keys()),
				title="–†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –Ω–∞—Å—Ç—Ä–æ–µ–Ω–∏–π –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–π"
			)
			st.plotly_chart(fig, use_container_width=True)
		else:
			st.info("–ù–µ—Ç –¥–∞–Ω–Ω—ã—Ö –æ –Ω–∞—Å—Ç—Ä–æ–µ–Ω–∏—è—Ö")
	
	with col2:
		st.subheader("–≠–º–æ—Ü–∏–∏ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–π")
		if ux_stats['emotions']:
			fig = px.bar(
				x=list(ux_stats['emotions'].keys()),
				y=list(ux_stats['emotions'].values()),
				title="–û–±–Ω–∞—Ä—É–∂–µ–Ω–Ω—ã–µ —ç–º–æ—Ü–∏–∏ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–π"
			)
			st.plotly_chart(fig, use_container_width=True)
		else:
			st.info("–ù–µ—Ç –¥–∞–Ω–Ω—ã—Ö –æ–± —ç–º–æ—Ü–∏—è—Ö")
	
	# Sentiment over time
	st.subheader("üìà –¢—Ä–µ–Ω–¥—ã –Ω–∞—Å—Ç—Ä–æ–µ–Ω–∏–π")
	sentiment_timeline = []
	
	for conv in conversations:
		if 'analysis' in conv and 'ux' in conv['analysis']:
			ux_analysis = conv['analysis']['ux']
			if 'sentiment' in ux_analysis:
				sentiment_timeline.append({
					'date': datetime.fromisoformat(conv['start_time']).date(),
					'sentiment': ux_analysis['sentiment'],
					'confidence': ux_analysis.get('sentiment_confidence', 0)
				})
	
	if sentiment_timeline:
		sentiment_df = pd.DataFrame(sentiment_timeline)
		
		# Group by date and calculate sentiment scores
		sentiment_scores = {'positive': 1, 'neutral': 0, 'negative': -1}
		sentiment_df['score'] = sentiment_df['sentiment'].map(sentiment_scores)
		
		daily_sentiment = sentiment_df.groupby('date')['score'].mean().reset_index()
		
		fig = px.line(daily_sentiment, x='date', y='score', 
					 title="–ï–∂–µ–¥–Ω–µ–≤–Ω—ã–µ —Ç—Ä–µ–Ω–¥—ã –Ω–∞—Å—Ç—Ä–æ–µ–Ω–∏–π",
					 labels={'score': '–û—Ü–µ–Ω–∫–∞ –Ω–∞—Å—Ç—Ä–æ–µ–Ω–∏—è', 'date': '–î–∞—Ç–∞'})
		fig.add_hline(y=0, line_dash="dash", line_color="gray")
		st.plotly_chart(fig, use_container_width=True)

def show_agent_performance(conversations):
	st.header("ü§ñ Agent Performance Analysis")
	
	# Extract agent data
	agent_data = []
	
	for conv in conversations:
		agent_types = conv.get('agent_types', [])
		is_successful = False
		if 'analysis' in conv and 'ux' in conv['analysis']:
			is_successful = conv['analysis']['ux'].get('is_successful', False)
		
		if agent_types:
			for agent in agent_types:
				agent_data.append({
					'agent': agent,
					'success': is_successful,
					'duration': conv['duration_minutes'],
					'messages': conv['message_count']
				})
	
	if agent_data:
		agent_df = pd.DataFrame(agent_data)
		
		col1, col2 = st.columns(2)
		
		with col1:
			# Agent usage frequency
			agent_counts = agent_df['agent'].value_counts()
			fig = px.bar(
				x=agent_counts.index,
				y=agent_counts.values,
				title="Agent Usage Frequency"
			)
			st.plotly_chart(fig, use_container_width=True)
		
		with col2:
			# Agent success rates
			success_rates = agent_df.groupby('agent')['success'].mean()
			fig = px.bar(
				x=success_rates.index,
				y=success_rates.values,
				title="Agent Success Rates"
			)
			fig.update_layout(yaxis=dict(tickformat='.1%'))
			st.plotly_chart(fig, use_container_width=True)
		
		# Performance metrics table
		st.subheader("üìä Agent Performance Metrics")
		performance_metrics = agent_df.groupby('agent').agg({
			'success': ['count', 'mean'],
			'duration': 'mean',
			'messages': 'mean'
		}).round(2)
		
		performance_metrics.columns = ['Total Interactions', 'Success Rate', 'Avg Duration (min)', 'Avg Messages']
		st.dataframe(performance_metrics, use_container_width=True)
		
	else:
		st.info("No agent performance data available")
		st.write("Most conversations appear to be handled without specific agent assignments.")

if __name__ == "__main__":
	main()