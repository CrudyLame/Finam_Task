{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Baseline Conversation Analysis\n",
    "\n",
    "This notebook loads conversation data from CSV, parses it into Conversation objects, processes them with OpenAI LLM analysis, and saves the results to JSON."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "from typing import List\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Add utils to path\n",
    "sys.path.append('utils')\n",
    "\n",
    "# Import custom modules\n",
    "from utils.conv.parser import ConversationParser\n",
    "from utils.conv.conversation import Conversation, ConversationMap\n",
    "from utils.llm import ConversationMapper"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load and Parse Conversations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parsing conversations from CSV...\n",
      "Parsed 2055 conversations\n",
      "Total users: 150\n"
     ]
    }
   ],
   "source": [
    "# Initialize parser\n",
    "parser = ConversationParser(\n",
    "    csv_file_path='data/data.csv',\n",
    "    time_threshold_minutes=30\n",
    ")\n",
    "\n",
    "print(\"Parsing conversations from CSV...\")\n",
    "conversations = parser.parse_conversations()\n",
    "\n",
    "print(f\"Parsed {len(conversations)} conversations\")\n",
    "print(f\"Total users: {len(set(c.user_id for c in conversations))}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Display Basic Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Conversation Statistics ===\n",
      "total_conversations: 2055\n",
      "total_messages: 13194\n",
      "unique_users: 150\n",
      "avg_duration_minutes: 0.7400405515004055\n",
      "avg_message_count: 6.420437956204379\n",
      "\n",
      "=== Sample Conversations ===\n",
      "\n",
      "Conversation 1:\n",
      "  ID: 1\n",
      "  User: 2147\n",
      "  Duration: 0.1 minutes\n",
      "  Messages: 3\n",
      "  Text preview: Напиши, ФИО_1 пожелание \"Хорошего дня!\"\n",
      "Вы хотите отправить сообщение ФИО_1 с пожеланием \"Хорошего д...\n",
      "\n",
      "Conversation 2:\n",
      "  ID: 2\n",
      "  User: 2147\n",
      "  Duration: 0.2 minutes\n",
      "  Messages: 3\n",
      "  Text preview: Отправить сообщение\n",
      "Сообщение с пожеланием \"Хорошего дня!\" успешно отправлено ФИО_1. Если нужно что-...\n",
      "\n",
      "Conversation 3:\n",
      "  ID: 3\n",
      "  User: 4071\n",
      "  Duration: 0.1 minutes\n",
      "  Messages: 3\n",
      "  Text preview: напиши кокориной елене спасибо\n",
      "Вы хотите отправить сообщение ФИО_2 с текстом \"спасибо\" или записать ...\n"
     ]
    }
   ],
   "source": [
    "# Get basic statistics\n",
    "stats = parser.get_conversation_stats(conversations)\n",
    "\n",
    "print(\"\\n=== Conversation Statistics ===\")\n",
    "for key, value in stats.items():\n",
    "    print(f\"{key}: {value}\")\n",
    "\n",
    "# Display sample conversations\n",
    "print(\"\\n=== Sample Conversations ===\")\n",
    "for i, conv in enumerate(conversations[:3]):\n",
    "    print(f\"\\nConversation {i+1}:\")\n",
    "    print(f\"  ID: {conv.dialogue_id}\")\n",
    "    print(f\"  User: {conv.user_id}\")\n",
    "    print(f\"  Duration: {conv.duration_minutes:.1f} minutes\")\n",
    "    print(f\"  Messages: {conv.message_count}\")\n",
    "    print(f\"  Text preview: {conv.full_text[:100]}...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Process with OpenAI LLM Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing 5 conversations with OpenAI...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Analyzing conversations: 100%|██████████| 5/5 [01:11<00:00, 14.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully analyzed 5 conversations\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Initialize conversation mapper\n",
    "mapper = ConversationMapper()\n",
    "\n",
    "# Process a small batch first for testing\n",
    "test_batch_size = 5\n",
    "test_conversations = conversations[:test_batch_size]\n",
    "\n",
    "print(f\"Processing {len(test_conversations)} conversations with OpenAI...\")\n",
    "\n",
    "# Process conversations with progress bar\n",
    "analyzed_conversations = []\n",
    "for conv in tqdm(test_conversations, desc=\"Analyzing conversations\"):\n",
    "    analyzed_conv = mapper.map_conversation(conv)\n",
    "    analyzed_conversations.append(analyzed_conv)\n",
    "\n",
    "print(f\"Successfully analyzed {len(analyzed_conversations)} conversations\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Display Analysis Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Sample Analysis Results ===\n",
      "Sentiment: SentimentType.NEUTRAL (confidence: 0.85)\n",
      "Emotions: []\n",
      "Problems: [<ProblemType.USER_CONFUSION: 'user_confusion'>]\n",
      "Problem Severity: 3/10\n",
      "Categories: [<CategoryType.COMMUNICATION: 'communication'>, <CategoryType.OTHER: 'other'>]\n",
      "Intent: [<IntentType.GENERAL_INFO: 'general_info'>]\n",
      "Feedback: []\n",
      "Suggestions: []\n",
      "Is Successful: False\n"
     ]
    }
   ],
   "source": [
    "# Display analysis results for the first conversation\n",
    "if analyzed_conversations and analyzed_conversations[2].analysis:\n",
    "    sample_analysis = analyzed_conversations[2].analysis\n",
    "    \n",
    "    print(\"\\n=== Sample Analysis Results ===\")\n",
    "    print(f\"Sentiment: {sample_analysis.sentiment} (confidence: {sample_analysis.sentiment_confidence:.2f})\")\n",
    "    print(f\"Emotions: {sample_analysis.emotions}\")\n",
    "    print(f\"Problems: {sample_analysis.problems}\")\n",
    "    print(f\"Problem Severity: {sample_analysis.problem_severity}/10\")\n",
    "    print(f\"Categories: {sample_analysis.category}\")\n",
    "    print(f\"Intent: {sample_analysis.intent}\")\n",
    "    print(f\"Feedback: {sample_analysis.feedback}\")\n",
    "    print(f\"Suggestions: {sample_analysis.suggestions}\")\n",
    "    print(f\"Is Successful: {sample_analysis.is_successful}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "# Install dependencies for lightweight LLM providers (run once)\n# Uncomment the provider you want to use:\n\n# For Hugging Face models (FREE, local inference)\n# !pip install transformers torch accelerate bitsandbytes\n\n# For Groq API (FAST, requires free API key)\n# !pip install groq\n\n# For Ollama (LOCAL, requires Ollama server)\n# !pip install ollama\n\nprint(\"Dependencies installation cell - uncomment the provider you want to use above\")",
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {},
   "outputs": [],
   "source": "# Enhanced mass processing with support for multiple LLM providers\nimport asyncio\nimport time\nfrom utils.conv_processor import ConversationProcessor\n\n# ==================== LLM CONFIGURATION ====================\n# Choose your LLM provider and configure parameters\n\n# Option 1: OpenAI (original - requires API key and credits)\n# llm_config = {\n#     'llm_provider': 'openai',\n#     'openai_client': None  # Uses default OpenAI client\n# }\n\n# Option 2: Hugging Face (FREE - runs locally on Kaggle)\nllm_config = {\n    'llm_provider': 'huggingface',\n    'model_name': 'microsoft/Phi-3-mini-4k-instruct'  # Fast 3.8B model\n    # Alternative options:\n    # 'model_name': 'google/gemma-2b-it'  # Even faster 2B model\n    # 'model_name': 'microsoft/DialoGPT-medium'  # Fastest 345M model\n}\n\n# Option 3: Groq (FAST - requires free API key)\n# llm_config = {\n#     'llm_provider': 'groq',\n#     'api_key': 'your_groq_api_key_here',\n#     'model_name': 'llama3-8b-8192'  # Fast inference\n# }\n\n# Option 4: Ollama (LOCAL - requires Ollama running)\n# llm_config = {\n#     'llm_provider': 'ollama',\n#     'model_name': 'llama3.1:8b',\n#     'base_url': 'http://localhost:11434'\n# }\n\n# ==================== PROCESSING CONFIGURATION ====================\nprocessing_config = {\n    'max_concurrent_requests': 5,  # Reduce for lighter models\n    'batch_size': 25,  # Smaller batches for stability\n    'progress_file': f\"processing_progress_{llm_config['llm_provider']}.json\",\n    'results_file': f\"analyzed_conversations_{llm_config['llm_provider']}.json\"\n}\n\n# ==================== INITIALIZE AND RUN ====================\nprint(f\"Using LLM provider: {llm_config['llm_provider']}\")\nprint(f\"Model: {llm_config.get('model_name', 'default')}\")\n\n# Initialize processor\nprocessor = ConversationProcessor(\n    **processing_config,\n    **llm_config\n)\n\n# Handle resume processing\nshould_resume, start_index = processor.resume_processing_prompt(len(conversations))\n\n# Get user confirmation\nif processor.get_user_confirmation(len(conversations), start_index):\n    print(f\"Starting processing with {llm_config['llm_provider']} provider...\")\n    print(f\"Processing {len(conversations) - start_index} conversations...\")\n    \n    # Run the concurrent processing\n    start_time = time.time()\n    results = await processor.process_conversations_concurrent(conversations, start_index)\n    end_time = time.time()\n    \n    print(f\"\\n=== Processing Complete ===\")\n    print(f\"Provider: {llm_config['llm_provider']}\")\n    print(f\"Total time: {end_time - start_time:.2f} seconds\")\n    print(f\"Results saved to: {processor.results_file}\")\n    print(f\"Average time per conversation: {(end_time - start_time) / (len(conversations) - start_index):.2f} seconds\")\n    \n    # Clean up progress file\n    processor.cleanup_progress()\n    \n    analyzed_conversations = results\n    \nelse:\n    print(\"Processing cancelled\")\n    analyzed_conversations = []"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Save Results to JSON"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert to JSON-serializable format\n",
    "def conversation_to_dict(conv: Conversation) -> dict:\n",
    "    \"\"\"Convert Conversation object to dictionary for JSON serialization\"\"\"\n",
    "    result = {\n",
    "        'dialogue_id': conv.dialogue_id,\n",
    "        'user_id': conv.user_id,\n",
    "        'start_time': conv.start_time.isoformat(),\n",
    "        'end_time': conv.end_time.isoformat(),\n",
    "        'duration_minutes': conv.duration_minutes,\n",
    "        'message_count': conv.message_count,\n",
    "        'full_text': conv.full_text,\n",
    "        'departments': conv.departments,\n",
    "        'analysis': None\n",
    "    }\n",
    "    \n",
    "    if conv.analysis:\n",
    "        result['analysis'] = {\n",
    "            'sentiment': conv.analysis.sentiment,\n",
    "            'sentiment_confidence': conv.analysis.sentiment_confidence,\n",
    "            'emotions': conv.analysis.emotions,\n",
    "            'problems': conv.analysis.problems,\n",
    "            'problem_severity': conv.analysis.problem_severity,\n",
    "            'problem_extra_info': conv.analysis.problem_extra_info,\n",
    "            'success_indicators': conv.analysis.success_indicators,\n",
    "            'failure_indicators': conv.analysis.failure_indicators,\n",
    "            'category': conv.analysis.category,\n",
    "            'intent': conv.analysis.intent,\n",
    "            'feedback': conv.analysis.feedback,\n",
    "            'suggestions': conv.analysis.suggestions,\n",
    "            'analysis_explanation': conv.analysis.analysis_explanation\n",
    "        }\n",
    "    \n",
    "    return result\n",
    "\n",
    "# Convert all conversations to dictionaries\n",
    "conversations_dict = [conversation_to_dict(conv) for conv in analyzed_conversations]\n",
    "\n",
    "# Create output data structure\n",
    "output_data = {\n",
    "    'metadata': {\n",
    "        'total_conversations': len(conversations_dict),\n",
    "        'processed_at': datetime.now().isoformat(),\n",
    "        'source_file': 'data/data.csv',\n",
    "        'time_threshold_minutes': 30\n",
    "    },\n",
    "    'conversations': conversations_dict\n",
    "}\n",
    "\n",
    "# Save to JSON file\n",
    "output_filename = f'analyzed_conversations_{datetime.now().strftime(\"%Y%m%d_%H%M%S\")}.json'\n",
    "with open(output_filename, 'w', encoding='utf-8') as f:\n",
    "    json.dump(output_data, f, ensure_ascii=False, indent=2)\n",
    "\n",
    "print(f\"\\nResults saved to: {output_filename}\")\n",
    "print(f\"Total conversations processed: {len(conversations_dict)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Analysis Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate summary statistics\n",
    "analyzed_with_results = [conv for conv in analyzed_conversations if conv.analysis]\n",
    "\n",
    "if analyzed_with_results:\n",
    "    print(\"\\n=== Analysis Summary ===\")\n",
    "    print(f\"Conversations with analysis: {len(analyzed_with_results)}\")\n",
    "    \n",
    "    # Sentiment distribution\n",
    "    sentiment_counts = {}\n",
    "    for conv in analyzed_with_results:\n",
    "        sentiment = conv.analysis.sentiment\n",
    "        sentiment_counts[sentiment] = sentiment_counts.get(sentiment, 0) + 1\n",
    "    \n",
    "    print(\"\\nSentiment Distribution:\")\n",
    "    for sentiment, count in sentiment_counts.items():\n",
    "        percentage = (count / len(analyzed_with_results)) * 100\n",
    "        print(f\"  {sentiment}: {count} ({percentage:.1f}%)\")\n",
    "    \n",
    "    # Problem severity distribution\n",
    "    severities = [conv.analysis.problem_severity for conv in analyzed_with_results]\n",
    "    avg_severity = sum(severities) / len(severities)\n",
    "    print(f\"\\nAverage Problem Severity: {avg_severity:.2f}/10\")\n",
    "    \n",
    "    # Category distribution\n",
    "    category_counts = {}\n",
    "    for conv in analyzed_with_results:\n",
    "        for category in conv.analysis.category:\n",
    "            category_counts[category] = category_counts.get(category, 0) + 1\n",
    "    \n",
    "    print(\"\\nTop Categories:\")\n",
    "    for category, count in sorted(category_counts.items(), key=lambda x: x[1], reverse=True):\n",
    "        print(f\"  {category}: {count}\")\n",
    "else:\n",
    "    print(\"No conversations were successfully analyzed.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Data Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Validate the saved JSON file\n",
    "print(\"\\n=== Data Validation ===\")\n",
    "try:\n",
    "    with open(output_filename, 'r', encoding='utf-8') as f:\n",
    "        loaded_data = json.load(f)\n",
    "    \n",
    "    print(f\"✓ JSON file is valid\")\n",
    "    print(f\"✓ Contains {len(loaded_data['conversations'])} conversations\")\n",
    "    print(f\"✓ Metadata: {loaded_data['metadata']}\")\n",
    "    \n",
    "    # Check if analysis data is present\n",
    "    analyzed_count = sum(1 for conv in loaded_data['conversations'] if conv['analysis'])\n",
    "    print(f\"✓ {analyzed_count} conversations have analysis data\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"✗ Error validating JSON file: {e}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}